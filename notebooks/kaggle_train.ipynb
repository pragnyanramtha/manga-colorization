{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manga Colorizer â€” LoRA Training on Kaggle (2x T4)\n",
    "\n",
    "This notebook trains a style-specific LoRA on Kaggle using `kohya-ss/sd-scripts`.\n",
    "Upload your preprocessed dataset (from `python main.py preprocess`) before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install kohya_ss training scripts and dependencies\n",
    "!pip install -q torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q xformers\n",
    "!git clone https://github.com/kohya-ss/sd-scripts.git /kaggle/working/sd-scripts\n",
    "!pip install -q -r /kaggle/working/sd-scripts/requirements.txt\n",
    "!pip install -q accelerate safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURATION ===\n",
    "# Modify these paths for your Kaggle dataset\n",
    "\n",
    "BASE_MODEL = \"gsdf/Counterfeit-V3.0\"\n",
    "DATASET_DIR = \"/kaggle/input/your-dataset\"  # Upload your dataset here\n",
    "OUTPUT_DIR = \"/kaggle/working/lora_output\"\n",
    "LORA_NAME = \"manga_style_lora\"\n",
    "\n",
    "# Training hyperparameters (tuned for 2x T4, 200 images)\n",
    "RESOLUTION = 512\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-4\n",
    "NETWORK_DIM = 32  # LoRA rank\n",
    "NETWORK_ALPHA = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Create dataset metadata for kohya training\n",
    "dataset_config = {\n",
    "    \"general\": {\n",
    "        \"resolution\": RESOLUTION,\n",
    "        \"shuffle_caption\": False,\n",
    "        \"keep_tokens\": 0,\n",
    "    },\n",
    "    \"datasets\": [\n",
    "        {\n",
    "            \"subsets\": [\n",
    "                {\n",
    "                    \"image_dir\": str(Path(DATASET_DIR) / \"train_color\"),\n",
    "                    \"conditioning_data_dir\": str(Path(DATASET_DIR) / \"train_bw\"),\n",
    "                    \"caption_extension\": \".txt\",\n",
    "                    \"num_repeats\": 5,\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "config_path = f\"{OUTPUT_DIR}/dataset_config.json\"\n",
    "with open(config_path, \"w\") as f:\n",
    "    json.dump(dataset_config, f, indent=2)\n",
    "\n",
    "# Create blank caption files (no text prompts needed)\n",
    "color_dir = Path(DATASET_DIR) / \"train_color\"\n",
    "if color_dir.exists():\n",
    "    for img in color_dir.iterdir():\n",
    "        if img.suffix.lower() in {\".png\", \".jpg\", \".jpeg\", \".webp\"}:\n",
    "            caption_file = img.with_suffix(\".txt\")\n",
    "            if not caption_file.exists():\n",
    "                caption_file.write_text(\"\")\n",
    "\n",
    "print(f\"Config saved to: {config_path}\")\n",
    "if color_dir.exists():\n",
    "    print(f\"Found {len(list(color_dir.glob('*.png')))} training images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=\"gsdf/Counterfeit-V3.0\",\n",
    "    filename=\"Counterfeit-V3.0_fix_fp16.safetensors\",\n",
    "    cache_dir=\"/kaggle/working/models\",\n",
    ")\n",
    "print(f\"Base model: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch \\\n",
    "    --num_processes=1 \\\n",
    "    --mixed_precision=\"fp16\" \\\n",
    "    /kaggle/working/sd-scripts/train_network.py \\\n",
    "    --pretrained_model_name_or_path=\"{model_path}\" \\\n",
    "    --dataset_config=\"{config_path}\" \\\n",
    "    --output_dir=\"{OUTPUT_DIR}\" \\\n",
    "    --output_name=\"{LORA_NAME}\" \\\n",
    "    --save_model_as=\"safetensors\" \\\n",
    "    --max_train_epochs={EPOCHS} \\\n",
    "    --learning_rate={LEARNING_RATE} \\\n",
    "    --optimizer_type=\"AdamW8bit\" \\\n",
    "    --network_module=\"networks.lora\" \\\n",
    "    --network_dim={NETWORK_DIM} \\\n",
    "    --network_alpha={NETWORK_ALPHA} \\\n",
    "    --train_batch_size={BATCH_SIZE} \\\n",
    "    --resolution=\"{RESOLUTION},{RESOLUTION}\" \\\n",
    "    --mixed_precision=\"fp16\" \\\n",
    "    --save_precision=\"fp16\" \\\n",
    "    --xformers \\\n",
    "    --cache_latents \\\n",
    "    --gradient_checkpointing \\\n",
    "    --seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "lora_path = f\"{OUTPUT_DIR}/{LORA_NAME}.safetensors\"\n",
    "if os.path.exists(lora_path):\n",
    "    size_mb = os.path.getsize(lora_path) / (1024 * 1024)\n",
    "    print(f\"LoRA saved: {lora_path} ({size_mb:.1f} MB)\")\n",
    "    print(\"Download this file and use with:\")\n",
    "    print(\"  python main.py colorize panel.png ref.png --lora path/to/lora.safetensors\")\n",
    "else:\n",
    "    print(\"ERROR: LoRA file not found. Check training logs above.\")\n",
    "    for f in os.listdir(OUTPUT_DIR):\n",
    "        print(f\"  {f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
